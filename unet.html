<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>unet_hippocampus</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="unet_hippocampus_files/libs/clipboard/clipboard.min.js"></script>
<script src="unet_hippocampus_files/libs/quarto-html/quarto.js"></script>
<script src="unet_hippocampus_files/libs/quarto-html/popper.min.js"></script>
<script src="unet_hippocampus_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="unet_hippocampus_files/libs/quarto-html/anchor.min.js"></script>
<link href="unet_hippocampus_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="unet_hippocampus_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="unet_hippocampus_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="unet_hippocampus_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="unet_hippocampus_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets <span class="im">as</span> datasets</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader <span class="im">as</span> DataLoader</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms <span class="im">as</span> transforms</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset, random_split</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os.path</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms.functional <span class="im">as</span> TF</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> save_image</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="1e13a4e2-6605-42ac-a1df-a3185860588d" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">'/content/drive/'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pwd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mounted at /content/drive/
/content</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> img_dataset(Dataset):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, kind<span class="op">=</span><span class="st">'train'</span>, transforms<span class="op">=</span><span class="va">False</span>, center_crop<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.center_crop <span class="op">=</span> center_crop</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.transforms <span class="op">=</span> transforms</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.kind <span class="op">=</span> kind</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(Dataset,<span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    path_kind <span class="op">=</span> <span class="st">'drive/MyDrive/hippocampus/'</span> <span class="op">+</span> kind</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.features <span class="op">=</span> [cv2.cvtColor(cv2.imread(<span class="bu">file</span>),cv2.COLOR_BGR2GRAY) <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> glob.glob(path_kind<span class="op">+</span><span class="st">'/Total/*.jpg'</span>)]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.targets <span class="op">=</span> [cv2.cvtColor(cv2.imread(<span class="bu">file</span>),cv2.COLOR_BGR2GRAY) <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> glob.glob(path_kind<span class="op">+</span><span class="st">'/label/*.jpg'</span>)]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(<span class="va">self</span>.features) <span class="op">==</span> <span class="bu">len</span>(<span class="va">self</span>.targets), <span class="st">"Something wrong with the dataset"</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.features)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    feature, target <span class="op">=</span> <span class="va">self</span>.features[index], <span class="va">self</span>.targets[index]</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    feature_tensor <span class="op">=</span> torch.tensor(feature)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    feature_tensor <span class="op">=</span> torch.unsqueeze(feature_tensor<span class="op">/</span><span class="dv">255</span>, <span class="dv">0</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    target_tensor <span class="op">=</span> torch.tensor(target)<span class="op">/</span><span class="dv">255</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    target_tensor <span class="op">=</span> torch.<span class="bu">round</span>(target_tensor)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    target_tensor <span class="op">=</span> torch.unsqueeze(target_tensor, <span class="dv">0</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.center_crop:</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>      feature_tensor <span class="op">=</span> TF.center_crop(feature_tensor, <span class="dv">150</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>      target_tensor <span class="op">=</span> TF.center_crop(target_tensor, <span class="dv">150</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.transforms:</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> <span class="va">self</span>.kind <span class="op">==</span> <span class="st">'train'</span> <span class="kw">or</span> <span class="va">self</span>.kind <span class="op">==</span> <span class="st">'balanced_train'</span>:</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> random.uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&gt;</span> <span class="fl">0.8</span>:</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                x_unif <span class="op">=</span> random.uniform(<span class="fl">0.5</span>, <span class="fl">1.5</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                feature_tensor <span class="op">=</span> TF.adjust_gamma(feature_tensor, x_unif)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> random.uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&gt;</span> <span class="fl">0.8</span>:</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                x1 <span class="op">=</span> np.random.binomial(<span class="dv">4</span>, <span class="fl">0.5</span>) <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>                y1 <span class="op">=</span> np.random.binomial(<span class="dv">4</span>, <span class="fl">0.5</span>) <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>                x2 <span class="op">=</span> random.uniform(<span class="fl">0.9</span>, <span class="fl">1.1</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>                x3 <span class="op">=</span> random.uniform(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>                feature_tensor <span class="op">=</span> TF.affine(feature_tensor, angle<span class="op">=</span><span class="dv">0</span>, translate <span class="op">=</span> [x1, y1], scale <span class="op">=</span> x2, shear<span class="op">=</span>x3)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>                target_tensor <span class="op">=</span> TF.affine(target_tensor, angle<span class="op">=</span><span class="dv">0</span>, translate <span class="op">=</span> [x1, y1], scale <span class="op">=</span> x2, shear<span class="op">=</span>x3) <span class="co"># think it's needed because of shear (?)</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> random.uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&gt;</span> <span class="fl">0.8</span>:</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>                feature_tensor <span class="op">=</span> TF.gaussian_blur(feature_tensor, <span class="dv">3</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> feature_tensor, target_tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="7324e701-3d73-4d3b-91b7-d641c27f8a73" data-execution_count="8">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example features and targets</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>val_dataloader <span class="op">=</span> DataLoader(img_dataset(kind<span class="op">=</span><span class="st">'validation'</span>), batch_size<span class="op">=</span><span class="dv">8</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> validation_features, validation_targets <span class="kw">in</span> val_dataloader:</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    u<span class="op">+=</span><span class="dv">1</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> u<span class="op">==</span><span class="dv">14</span>:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>          <span class="cf">break</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>figure,axis <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">8</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  axis[<span class="dv">0</span>,i].imshow(torch.squeeze(validation_features[i], <span class="dv">0</span>).numpy())</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  axis[<span class="dv">1</span>,i].imshow(torch.squeeze(validation_targets[i], <span class="dv">0</span>).numpy())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unet_hippocampus_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DoubleConv(nn.Module):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, out_channels, batchnorm<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(DoubleConv, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.batchnorm <span class="op">=</span> batchnorm</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.batchnorm:</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        nn.BatchNorm2d(out_channels),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(out_channels, out_channels, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        nn.BatchNorm2d(out_channels),</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(in_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        nn.Conv2d(out_channels, out_channels, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.conv(x)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_xavier(model, retrain_seed):</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>  torch.manual_seed(retrain_seed)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> init_weights(m):</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">type</span>(m) <span class="op">==</span> nn.Linear <span class="kw">and</span> m.weight.requires_grad <span class="kw">and</span> m.bias.requires_grad:</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>      g <span class="op">=</span> nn.init.calculta_gain(<span class="st">'tanh'</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>      torch.nn.init.xavier_uniform_(m.weight, gain<span class="op">=</span>g)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>      m.bias.data.fill_(<span class="dv">0</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>  model.<span class="bu">apply</span>(init_weights)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UNet(nn.Module):</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels<span class="op">=</span><span class="dv">1</span>, out_channels<span class="op">=</span><span class="dv">1</span>, features<span class="op">=</span>[<span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">256</span>, <span class="dv">512</span>], batchnorm<span class="op">=</span><span class="va">False</span>, initialization<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(UNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.batchnorm <span class="op">=</span> batchnorm</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.initialization <span class="op">=</span> initialization</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.name <span class="op">=</span> <span class="ss">f'UNet_batchnorm_</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>batchnorm<span class="sc">}</span><span class="ss">_initialization_</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>initialization<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.downs <span class="op">=</span> nn.ModuleList()</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.ups <span class="op">=</span> nn.ModuleList()</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Down part of UNet</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feature <span class="kw">in</span> features:</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.downs.append(DoubleConv(in_channels, feature, batchnorm<span class="op">=</span><span class="va">self</span>.batchnorm))</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>      in_channels <span class="op">=</span> feature</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up part of UNet</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feature <span class="kw">in</span> <span class="bu">reversed</span>(features):</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.ups.append(nn.ConvTranspose2d(feature<span class="op">*</span><span class="dv">2</span>, feature, kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)) <span class="co">#feature*2 because of concatination</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.ups.append(DoubleConv(feature<span class="op">*</span><span class="dv">2</span>, feature, batchnorm<span class="op">=</span><span class="va">self</span>.batchnorm))</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bottleneck</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bottleneck <span class="op">=</span> DoubleConv(features[<span class="op">-</span><span class="dv">1</span>], features[<span class="op">-</span><span class="dv">1</span>]<span class="op">*</span><span class="dv">2</span>, batchnorm<span class="op">=</span><span class="va">self</span>.batchnorm)</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Final Conv</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.final_conv <span class="op">=</span> nn.Conv2d(features[<span class="dv">0</span>], out_channels, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>    skip_connections <span class="op">=</span> []</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> down <span class="kw">in</span> <span class="va">self</span>.downs:</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> down(x)</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>      skip_connections.append(x) <span class="co"># first has highest resolution</span></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> <span class="va">self</span>.pool(x)</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.bottleneck(x)</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>    skip_connections <span class="op">=</span> skip_connections[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(<span class="va">self</span>.ups), <span class="dv">2</span>):</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> <span class="va">self</span>.ups[i](x) <span class="co">#ConvTranspose</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>      skip_connection <span class="op">=</span> skip_connections[i<span class="op">//</span><span class="dv">2</span>]</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> x.shape <span class="op">!=</span> skip_connection.shape:</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> transforms.functional.resize(x, skip_connection.shape[<span class="dv">2</span>:]) <span class="co">#ignoring batch size and channel size</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>      concat_skip <span class="op">=</span> torch.concat((skip_connection, x), dim<span class="op">=</span><span class="dv">1</span>) <span class="co">#dim=1 is channel dimension</span></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> <span class="va">self</span>.ups[i<span class="op">+</span><span class="dv">1</span>](concat_skip) <span class="co"># DoubleConv</span></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.final_conv(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> nn.Sigmoid()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> diceloss(nn.Module):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(diceloss, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, outcome, label):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">-</span>(<span class="dv">2</span><span class="op">*</span>(s(outcome)<span class="op">*</span>label).<span class="bu">sum</span>()<span class="op">+</span> <span class="fl">1e-5</span>) <span class="op">/</span> ((s(outcome)<span class="op">+</span>label).<span class="bu">sum</span>()<span class="op">+</span> <span class="fl">1e-8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batch_loss(outputs, labels, batch_size, criterion): <span class="co">#gives empty_loss and nempty_loss for batch</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  loss_empty_labels <span class="op">=</span> []</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  loss_not_empty_labels <span class="op">=</span> []</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.<span class="bu">sum</span>(labels[i]) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>      loss_empty_labels.append(criterion(outputs[i].detach(), labels[i]).item())</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>      loss_not_empty_labels.append(criterion(outputs[i].detach(), labels[i]).item())</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> loss_empty_labels, loss_not_empty_labels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(p_trdata, transforms, model, criterion, epochs, seed, crop<span class="op">=</span><span class="va">False</span>, balanced<span class="op">=</span><span class="va">False</span>): <span class="co">#epochs = tuple</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># make dataloaders</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'train'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> balanced:</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    tr_dataset <span class="op">=</span> img_dataset(kind<span class="op">=</span><span class="st">'train'</span>, transforms<span class="op">=</span>transforms, center_crop<span class="op">=</span>crop)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    tr_dataset <span class="op">=</span> img_dataset(kind<span class="op">=</span><span class="st">'balanced_train'</span>, transforms<span class="op">=</span>transforms, center_crop<span class="op">=</span>crop)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> p_trdata <span class="op">!=</span> <span class="dv">1</span>:</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>      keep <span class="op">=</span> math.floor(<span class="bu">len</span>(tr_dataset)<span class="op">*</span>p_trdata)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>      tr_dataset, _ <span class="op">=</span> random_split(tr_dataset, [keep, <span class="bu">len</span>(tr_dataset)<span class="op">-</span>keep], generator<span class="op">=</span>torch.Generator().manual_seed(seed))</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="bu">len</span>(tr_dataset))</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  tr_dataloader <span class="op">=</span> DataLoader(tr_dataset, batch_size<span class="op">=</span><span class="dv">8</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">del</span> tr_dataset</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'val'</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  val_dataset <span class="op">=</span> img_dataset(kind<span class="op">=</span><span class="st">'validation'</span>, transforms<span class="op">=</span><span class="va">False</span>, center_crop<span class="op">=</span>crop)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  val_dataloader <span class="op">=</span> DataLoader(val_dataset, batch_size<span class="op">=</span><span class="dv">8</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  <span class="kw">del</span> val_dataset</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'initialization'</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> model.initialization <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    init_xavier(model, seed)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>  s <span class="op">=</span> nn.Sigmoid() <span class="co"># for image saving</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># make folder</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'make folders'</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>  full_model_name <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>model<span class="sc">.</span>name<span class="sc">}</span><span class="ss">_transforms_</span><span class="sc">{</span>transforms<span class="sc">}</span><span class="ss">_criterion_</span><span class="sc">{</span>criterion<span class="sc">}</span><span class="ss">_ptrdata_</span><span class="sc">{</span>p_trdata<span class="sc">}</span><span class="ss">_seed_</span><span class="sc">{</span>seed<span class="sc">}</span><span class="ss">_crop_</span><span class="sc">{</span>crop<span class="sc">}</span><span class="ss">_balanced_</span><span class="sc">{</span>balanced<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>  path <span class="op">=</span> <span class="st">'drive/MyDrive/models/'</span><span class="op">+</span>full_model_name</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> os.path.isdir(path):</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    os.mkdir(path)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># train</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>  epochs_tr_empty_loss <span class="op">=</span> []</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>  epochs_tr_nempty_loss <span class="op">=</span> []</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>  epochs_tr_total_loss <span class="op">=</span> []</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>  epochs_val_empty_loss <span class="op">=</span> []</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>  epochs_val_nempty_loss <span class="op">=</span> []</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>  epochs_val_total_loss <span class="op">=</span> []</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>  min_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>  start_epoch, end_epoch <span class="op">=</span> epochs</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(start_epoch, end_epoch):</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(epoch)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>    empty_loss <span class="op">=</span> []</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>    nempty_loss <span class="op">=</span> []</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> []</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(tr_dataloader):</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>        inputs, labels <span class="op">=</span> data</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> labels.to(device)</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>        el, nel <span class="op">=</span> batch_loss(outputs, labels, outputs.shape[<span class="dv">0</span>], criterion)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>        empty_loss.extend(el)</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>        nempty_loss.extend(nel)</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>        total_loss.append(loss.item())</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># track training error once per epoch</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    epochs_tr_empty_loss.append(np.mean(np.array(empty_loss)))</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>    epochs_tr_nempty_loss.append(np.mean(np.array(nempty_loss)))</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>    epochs_tr_total_loss.append(np.mean(np.array(total_loss)))</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># track validation error once per epoch</span></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>    val_empty_loss <span class="op">=</span> []</span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>    val_nempty_loss <span class="op">=</span> []</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>    val_total_loss <span class="op">=</span> []</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(val_dataloader):</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>            inputs, labels <span class="op">=</span> data</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>            vel, vnel <span class="op">=</span> batch_loss(outputs, labels, outputs.shape[<span class="dv">0</span>], criterion)</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a>            vloss <span class="op">=</span> criterion(outputs, labels).item()</span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>            val_empty_loss.extend(vel)</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>            val_nempty_loss.extend(vnel)</span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>            val_total_loss.append(vloss)</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>    epochs_val_empty_loss.append(<span class="bu">round</span>(np.mean(np.array(val_empty_loss)), <span class="dv">5</span>))</span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>    epochs_val_nempty_loss.append(<span class="bu">round</span>(np.mean(np.array(val_nempty_loss)), <span class="dv">5</span>))</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>    epochs_val_total_loss.append(<span class="bu">round</span>(np.mean(np.array(val_total_loss)), <span class="dv">5</span>))</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>    <span class="co"># save model state if its better than the others</span></span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.mean(np.array(val_total_loss)) <span class="op">&lt;</span> min_val_loss:</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>      torch.save(model.state_dict(), path<span class="op">+</span><span class="st">'/model.pth'</span>)</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>      min_val_loss <span class="op">=</span> np.mean(np.array(val_total_loss))</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># save a predicted image once per epoch</span></span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">==</span> start_epoch:</span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>      u <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> validation_features, validation_targets <span class="kw">in</span> val_dataloader:</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>          u<span class="op">+=</span><span class="dv">1</span></span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> u<span class="op">==</span><span class="dv">14</span>:</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>      validation_features <span class="op">=</span> validation_features.to(device)</span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>      save_image(validation_targets[<span class="dv">4</span>], path<span class="op">+</span><span class="st">'/validation_target_nonempty.png'</span>)</span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>      save_image(validation_features[<span class="dv">4</span>], path<span class="op">+</span><span class="st">'/validation_feature_nonempty.png'</span>)</span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>      save_image(validation_targets[<span class="dv">0</span>], path<span class="op">+</span><span class="st">'/validation_target_empty.png'</span>)</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>      save_image(validation_features[<span class="dv">0</span>], path<span class="op">+</span><span class="st">'/validation_feature_empty.png'</span>)</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>      <span class="kw">del</span> validation_targets</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>    image_name_nempty <span class="op">=</span> <span class="ss">f'/validation_notempty_prediction_</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">.png'</span></span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a>    image_name_empty <span class="op">=</span> <span class="ss">f'/validation_empty_prediction_</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">.png'</span></span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> s(model(validation_features))</span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a>    save_image(predictions[<span class="dv">4</span>], path<span class="op">+</span>image_name_nempty)</span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>    save_image(predictions[<span class="dv">0</span>], path<span class="op">+</span>image_name_empty)</span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>  <span class="co"># save training and validation errors as csv</span></span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>  d <span class="op">=</span> {}</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>  d[<span class="st">'tr_empty'</span>] <span class="op">=</span> epochs_tr_empty_loss</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a>  d[<span class="st">'tr_not_empty'</span>] <span class="op">=</span> epochs_tr_nempty_loss</span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a>  d[<span class="st">'tr_total'</span>] <span class="op">=</span> epochs_tr_total_loss</span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a>  d[<span class="st">'val_empty'</span>] <span class="op">=</span> epochs_val_empty_loss</span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a>  d[<span class="st">'val_not_empty'</span>] <span class="op">=</span> epochs_val_nempty_loss</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a>  d[<span class="st">'val_total'</span>] <span class="op">=</span> epochs_val_total_loss</span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> pd.DataFrame(d)</span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a>  df.to_csv(path<span class="op">+</span><span class="ss">f'/losses_start</span><span class="sc">{</span>start_epoch<span class="sc">}</span><span class="ss">.txt'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="41c95541-681d-474f-cf25-276cd77e41da" data-execution_count="12">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>cuda</code></pre>
</div>
</div>
<div class="cell" data-outputid="cef7db37-93bd-421e-d70a-d1ff9433ea6e" data-execution_count="15">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion, optimizer, model =&gt; call train function</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>dice <span class="op">=</span> diceloss()</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>bce <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> UNet(batchnorm <span class="op">=</span> <span class="va">True</span>, initialization <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>train(p_trdata <span class="op">=</span> <span class="fl">0.2</span>, transforms <span class="op">=</span> <span class="va">False</span>, model <span class="op">=</span> model, criterion <span class="op">=</span> dice, epochs <span class="op">=</span> (<span class="dv">0</span>,<span class="dv">10</span>), crop<span class="op">=</span><span class="va">False</span>, balanced<span class="op">=</span><span class="va">True</span>, seed <span class="op">=</span> <span class="dv">1234</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>train
1193
val
initialization
make folders
0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1
2
3
4
5
6
7
8
9</code></pre>
</div>
</div>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>